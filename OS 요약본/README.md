## OS

### 1. Process vs Thread

#### 프로세스

: **실행 중인 프로그램**. 디스크로부터 **메모리에 적재되어 OS의 제어를 받을 수 있는 상태**가 되었다는 것. 자신만의 메모리 영역(주소공간)이 있음을 의미함.

운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며, 이것들을 총칭하여 프로세스라고 한다.

메모리 구조를 이루고, 프로그램 카운터나 레지스터처럼 현재 어떤 자원을 사용하는지 관련 정보가 들어있는 **동적인 개체**.

*cf) **프로그램** - 컴파일한 코드와 초기화 전역변수, 문자열 등 정적 데이터를 포함하는 정적인 개체.



#### 프로세스의 구조 (코드, 데이터, 스택, 힙)

- CODE - **일반 코드** 

  - 프로그래밍 코드 텍스트가 들어가는 메모리 영역 (**컴파일된 결과물**)
  - 실행 명령을 포함하는 메모리.
  - 프로세서가 **디스크에서 읽어 실행하는 컴파일된 프로그램을 저장**.
  - **읽기 전용**이므로, 프로그램이 코드 영역을 침범해 쓰기를 시도하면 오류 발생.

- DATA - **변수/초기화된 데이터** 

  - 프로그램의 **가상 주소공간**.
  - **변수의 메모리 영역이 저장**되는 공간 (코드에서 함수 선언 시, 변수가 가리키는 메모리 공간), 전역변수, 초기화된 데이터
  - **읽기/쓰기가 가능**한 영역.

- STACK - **임시 데이터(함수 호출, 지역변수 등)** 

  - **데이터를 일시적으로 저장**하는 영역.
  - **함수 내 지역변수 혹은 인자의 메모리 주소**가 위치하는 공간, **리턴 주소값**을 저장.
  - 변수가 범위 밖으로 이동하면 공간을 해제.
  - 함수를 호출할수록 커지고, 반환하면 줄어듦.
  - 힙과 인접한 방향으로 점점 커져 스택 포인터와 힙 포인터를 만나면 메모리가 소진됨.

- HEAP - **코드에서 동적으로 생성되는 데이터**

  - **동적으로 메모리를 할당**하기 위해, 프로그램 실행 중 **시스템 호출을 사용했다가 해제**.
  - 프로세스의 공유 라이브러리와 동적으로 적재된 모듈이 서로 공유.
  - 동적 메모리 할당이 발생하면 스택영역 쪽인 위쪽으로 커짐.

  ​       



#### 프로세스 동작 과정

- 프로그램이 실행되면 프로세스의 CODE 영역에 코드들이 전달됨.
- 이후, PC(Program Counter)가 코드가 존재하는 주소를 하나하나 가리키며 실행되고, 실행 중 필요시 STACK, HEAP, DATA 영역에 read/wirte를 실시.
- 연산 과정이 끝나면 STACK에서 차례로 다시 제거되며, 이후 모든 작업이 완료되면 프로그램 종료. 



#### PCB(Process Control Block)

: **특정 프로세스에 대한 중요한 정보를 저장하는 운영체제의 자료구조**. 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에! 고유한 PCB를 생성한다.(1PCB/1프로세스) 문맥 교환 시, 작업의 진행 상황을 모두 PCB에 저장하고, 다시 CPU를 할당받으면 PCB에 저장되어있던 내용을 불러와 그 시점부터 작업을 수행.



- PCB에 저장되는 정보?

  - 1) OS가 관리상 사용하는 정보
    - 프로세스 식별자 (Process ID, PID) - 프로세스 식별번호
    - 프로세스 상태 - new, ready, running, waiting, terminated 등
    - CPU 스케줄링 정보 - 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
  - 2) CPU 수행 관련 HW 값 (문맥 관련)
    - 프로그램 카운터 - 프로세스가 다음에 실행할 명령어의 주소
    - CPU 레지스터 - CPU가 요청을 처리하는데 필요한 데이터를 일시적으로 저장
  - 3) 메모리 관련
    - 메모리 관리 정보 - 페이지 테이블 / 세그먼트 테이블 등과 같은 정보
  - 4) 파일 관련
    - 입출력 상태 정보 - 프로세스에 할당된 입출력 장치들, 열린 파일 목록
    - 어카운팅 정보 - 사용된 CPU시간, 시간제한, 계정 번호 등



#### 스레드

: **프로세스의 실행 단위**. 한 프로세스 내에서 동작되는 여러 실행 흐름. 프로세스 내의 주소 공간이나 자원을 공유하여 실행됨. 

- 구성 (CPU 수행과 관련있는 것들을 독립적으로 가짐) => 하나의 PCB 내에 각 thread마다 별도의 copy 존재
  - thread ID
  - 프로그램 카운터
  - 레지스터 집합
  - **STACK** : 독립적인 실행 흐름(함수 호출)이 가능해야 하므로! (1스택/1스레드)
- 공유 자원 (동료 thread와 공유하는 부분 = task)
  - CODE section
  - DATA section
  - OS resources



### 2. Multi thread

: 여러 개의 프로세스를 두지 않고, 하나의 프로세스 내에 다중의 스레드를 두어 작업.



#### 장점

- 메모리 공간 낭비를 줄임, 시스템 자원 소모를 줄임 => 프로그램 응답 시간 단축
- 스레드 간 통신 방법 또한 훨씬 간단 (공유된 HEAP을 이용)
- 스레드 간 문맥 교환은 캐시 메모리를 비울 필요가 없어 더 빠름 => throughput 향상



#### 문제점

- 공유 자원에 대해 동시 접근하는 경우를 신경써야 함 (서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에, 다른 스레드에서 사용 중인 변수에 접근해 엉뚱하게 작동할 수 있기 때문!)

  => 동기화 작업 필요!! (작업 처리 순서 컨트롤, 공유 자원에 대한 접근 컨트롤)

- 병목현상 발생, 성능 저하 가능성 => 과도한 lock으로 인한 병목현상을 줄여야!

- 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있음



### 3. 스케줄러

: 프로세스를 스케줄링하기 위한 큐에 프로세스들을 넣고 빼주는 작업을 함.



- 프로세스를 스케줄링하기 위한 큐
  - Job queue - 현재 시스템 내에 있는 모든 프로세스의 집합
    - Ready queue - 현재 메모리 내에 있으면서, CPU를 잡아 실행되기를 기다리는 프로세스의 집합
    - Device queue - I/O device의 처리를 기다리는 프로세스의 집합



#### 장기 스케줄러 (Long-term Scheduler / Job Scheduler)

: 어떤 프로세스에 메모리를 할당하여 ready 큐로 보낼지 결정하는 역할.

- 메모리와 디스크 사이의 스케줄링 담당
- 프로세스에 메모리 및 각종 자원을 할당
- degree of Multiprogramming 제어 (실행 중인 프로세스의 수 제어)
- 프로세스의 상태를 new에서 ready로 바꿔줌

*메모리에 프로그램이 너무 많이/적게 올라가면 성능이 좋지 않음. time sharing system에서는 장기 스케줄러가 없고, 그냥 곧바로 메모리에 올라가는 ready 상태가 된다. (중기 스케줄러가 장기 스케줄러의 역할을 대신하는 격)



#### 단기 스케줄러 (Short-term Scheduler / CPU Scheduler)

: 어떤 프로세스에게 CPU를 줄지 결정하는 역할.

- CPU와 메모리 사이의 스케줄링 담당
- 프로세스의 CPU를 할당 (scheduler dispatch)
- 프로세스의 상태를 ready에서 running으로 바꿔줌 (또는 waiting -> running)



#### 중기 스케줄러 (Medium-term Scheduler / Swapper)

: 어떤 프로세스에게서 메모리를 뺏을지 결정하는 역할.

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swap out)
- 프로세스에게서 메모리를 deallocate
- degree of Multiprogramming 제어
- 프로세스의 상태를 ready에서 suspended로 바꿈

*blocked 상태에서는 스스로 ready 상태로 돌아갈 수 있지만, suspended되면 스스로 ready되지 못함.



### 4. CPU 스케줄러

: Ready queue에 있는 프로세스들을 대상으로, 누구에게 CPU를 줄지 결정.

- CPU 스케줄링이 필요한 이유?

  : CPU를 연속적으로 수행하는 단계와 I/O를 수행하는 단계가 섞여있기 때문. 

  - interactive job이 오래 기다리지 않도록 적절한 응답 요망
  - CPU와 I/O장치 등 시스템 자원을 골고루 효율적으로 사용하기 위함

- 스케줄링 성능 척도

  - 시스템 입장
    - CPU 이용률
    - Throughput (처리량)
  - 프로세스 입장
    - Turnaround time (소요시간, 반환시간) - 프로세스가 CPU를 쓰러 들어와서 일을 다 하고 나가기까지 걸린 시간
    - Waiting time (대기시간) - 프로세스가 ready 큐에서 순수하게 기다린 시간
    - Response time (응답시간) - 처음으로 CPU를 맛보기까지 걸린 시간



#### 스케줄링 알고리즘

- FCFS (First Come First Served)

  - 먼저 온 순서대로 처리
  - 비선점형 스케줄링
  - 할당된 CPU가 반환될 때에만 스케줄링이 이루어짐
  - **convoy effect** 발생 : 소요시간이 긴 프로세스가 먼저 도달하면 효율성이 떨어짐

- SJF (Shortest-Job-First)

  - CPU burst time이 짧은 프로세스를 먼저 처리
  - 비선점형
  - **starvation** 발생 : 사용 시간이 긴 프로세스는 영원히 CPU를 할당받을 수 없음

- SRT (Shortest Remaining time First)

  - 현재 수행중인 프로세스의 남은 CPU burst time 보다 더 짧은 burst time을 가지는 새로운 프로세스 도착 시, CPU를 뺏음
  - 선점형
  - 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어짐
  - **starvation** 발생 : 사용 시간이 긴 프로세스는 영원히 CPU를 할당받을 수 없음
  - **CPU burst time 예측 어려움** : 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문 (누가 언제 올지 모르잖아!)

- Priority Scheduling

  - 우선순위가 높은 프로세스에게 CPU를 할당 (정수로 표현, 작은 숫자일수록 우선순위 높음)
  - 선점형 ) 더 높은 우선순위의 프로세스가 도착하면, 실행 중인 프로세스를 멈추고 CPU를 선점.
  - 비선점형 ) 더 높은 우선순위의 프로세스가 도착하면, ready 큐의 head에 넣음.
  - **starvation** 발생 : 낮은 우선순위의 프로세스는 영원히 실행될 수 없음
  - **Aging** 으로 해결 : 아무리 우선순위가 낮아도, 오래 기다렸으면 우선순위가 올라가도록!

- Round Robin

  - 각 프로세스에게 동일한 크기의 할당 시간(quantum time)을 줌

  - 현대적인 CPU 스케줄링

  - 할당 시간이 지나면 프로세스는 선점당하고, ready 큐의 제일 뒤에 가서 다시 줄섬

  - CPU 사용 시간이 랜덤한 프로세스들이 섞여있을 경우 효과적

  - 장점

    - 응답 시간이 빨라짐 - 누구나 CPU를 조금이라도 맛볼 수 있기 때문. 

      n개의 프로세스가 q만큼 시간을 할당받았을 때, 각 프로세스는 1/n만큼의 시간을 얻고, 어떤 프로세스도 (n-1)q 이상 기다리지 않음.

    - 공정한 스케줄링 - CPU 사용 시간에 비례해서 ready 큐에서 기다림.

  - 주의점 (적당한 quantum time을 설정하는 것이 중요)

    - quantum time이 너무 크면 FCFS와 같아짐
    - quantum time이 너무 작으면, 잦은 문맥 교환으로 오버헤드 발생

 

### 5. 동기 vs 비동기

- 동기 : 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우. 그 전까지는 blocking 되어 있음. 구성이 단순하며, 순서대로 실행 가능하다. 하지만 멀티태스킹 불가.
- 비동기 : 반환 값을 기다리지 않고 (blocking 되지 않고), 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고, 바로 다음 코드를 실행. 멀티태스킹이 가능하지만, 일정 시간당 요청량이 많아질 경우 부하가 발생할 수 있어, 따로 핸들링 필요.





### 6. 프로세스 동기화

: 다중 프로세스 환경에서, 한 순간에 하나의 자원을 하나의 프로세스만이 이용하도록 제어하는 것.



#### critical section

: 동일 자원을 동시에 접근하는 작업을 실행하는 코드 영역.

critical section 문제해결을 위해, 

- 상호배제 (CS에는 하나의 프로세스만 진입)
- 진행 (CS에 어떤 프로세스도 존재하지 않을 때, 모든 프로세스가 진입 가능한 후보가 되어야 함)
- 한정된 대기 (CS 진입 횟수를 제한)



#### 해결책

#### 1) Lock

: 동시에 공유자원에 접근하는 것을 막기 위해, CS에 진입하는 프로세스가 lock을 획득, CS를 빠져나왔을 때 lock을 반납함으로써 동시접근을 막음. (HW기반)

하지만, 멀티 프로세서 환경에서는 시스템 효율 문제 때문에, test_and_set 같은 동기화 하드웨어 사용.



#### 2) Semaphore

: SW 상에서 Critical Section 문제를 해결하기 위한 동기화 도구.

여러 프로세스들에 의해 공유되는 변수이며, P(자원을 얻는)와 V(자원 반납)연산으로만 접근 가능.

- Counting Semaphore : 자원의 수를 나타냄
- Binary Semaphore : lock/unlock에 사용 (=MUTEX)



#### 단점

- 1) busy-waiting : 초기버전(spin lock)에서 CS에 진입해야 하는 프로세스는 진입 코드를 계속 반복. => CPU를 낭비하기 때문에 비효율적.

  일반적으로 block-wakeup 방식을 사용. (CS진입을 시도했으나 실패 시 block되고, 자리가 나면 wakeup해주는 방식)

- 2) Deadlock (교착상태) : CS에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되어야만 빠져나올 수 있는 상태. (서로 상대방에 의해 충족될 수 있는 event를 무한히 기다림)



#### 3) Monitor

: 고급 언어의 설계 구조물로서, 한 번에 하나의 프로세스만 모니터에서 활동하도록 보장해줌.

프로그래머가 동기화 제약 조건을 명시적으로 코딩할 필요가 없다.



### 7. 메모리 관리 전략

: **제한된 물리 메모리의 효율적 사용**(할당)과 **메모리 참조**(논리-물리 주소 할당) 방식을 제공하기 위한 전략.



#### -배경

: 멀티 프로세스 환경에서는 보다 좋은 성능을 위해 다수의 프로그램을 주 메모리에 올려놓아야 한다. 따라서, 적절한 메모리 위치에 프로그램을 적재해 효율적으로 메모리를 사용하고, 낭비를 막아야 함.



#### -Swapping

: 메모리 관리를 위해 사용되는 기법. 프로세스의 메모리를 보조기억장치(하드 디스크)로 내보내고(swap-out), 다른 프로세스의 메모리를 주기억장치(RAM)에 불러옴(swap-in).



**단편화(fragmentation)** 

: 프로세스들이 메모리에 적재되고, 제거되는 일이 반복되면서, 메모리에 생긴 사용하지 못할 만큼의 조각.

- **내부 단편화(Internal fragmentation)** - patition 크기가 프로세스 크기보다 크면, 메모리가 낭비됨
- **외부 단편화(External fragmentation)** - 총 남은 메모리 크기가 프로세스 크기보다 크지만, 연속된 공간이 아니라 적재될 수 없음. (메모리 낭비)



- **외부 단편화 문제 해결**
  - **공간 통합** (Coalescing holes) - 프로세스가 메모리를 반환하고 나가면, **인접한 빈 영역을 하나의 partition으로 통합**. (오버헤드 적음)
  - **메모리 압축** (Storage Compaction) - **모든 빈 공간을 하나로 통합**. 모든 프로세스를 재배치해야 함 (**오버헤드 매우 큼**). 많은 시스템 자원을 소비.



### 8. 가상 메모리

: **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록** 하는 기법. 

실제의 물리 메모리와 사용자의 논리 메모리의 개념을 분리해, 작은 메모리를 가지고도 얼마든지 큰 가상 주소공간을 제공할 수 있다.

#### 배경

이전에는 실행 코드 전부를 물리 메모리에 올려야 했고, 메모리 용량보다 큰 프로그램은 실행불가.



=> 프로그램의 일부분만 메모리에 올림으로써,

- 물리 메모리 크기 제약 X
- 더 많은 프로그램을 동시 실행 가능
- swap에 필요한 입출력이 줄어들어 프로그램 속도가 빨라짐.



#### 가상 메모리와 성능

- 가상 메모리와 메모리를 스왑하는 비용때문에 큰 성능 저하가 발생.
- 스와핑이 발생하지 않도록, 메모리 여유율을 유지하는 것이 성능에 중요.





#### 가상 메모리 기법

#### 1. Paging system : 프로그램을 같은 크기의 block(page, 보통 4KB)로 분할하여 비연속적으로 메인 메모리에 적재하는 방법. 

- 장점
  - 간단하고 효율적 (segmentation에 비해)
  - 외부 단편화 존재X 
  - 메모리 통합/압축 불필요
- 단점
  - page를 공유하거나 보호하는 과정이 복잡함 (segmentation에 비해) <- 프로그램의 논리적 구조 고려하지 않아서
  - 내부 단편화 발생 가능(자르다가 맨 마지막에 남는 부분 때문)
  - page mapping overhead
    - 메모리 공간과 추가적 메모리 접근이 필요 -> TLB활용으로 해결 가능



#### 2. Segmentation system : 프로그램을 논리적 block(segment. ex- stack, heap, main procedure, shared lib..)으로 분할해 비연속적으로 메인 메모리에 적재하는 방법.

- 장점

  - segment sharing / protection 용이

  - 내부 단편화 X 

- 단점

  - 외부 단편화 발생 가능
  - Address mapping 및 메모리 관리의 overhead가 큼 (paging system에 비해)
  - segment mapping overhead
    - 메모리 공간 / 추가적 메모리 접근 필요
    - 전용 HW 활용으로 해결 가능 (TLB)

![image-20210214223039281](C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\image-20210214223039281.png)

#### 3. Hybrid system : 프로그램을 논리단위의 segment로 분할하고, 각 segment를 고정된 크기의 page들로 분할해 page단위로 메모리에 적재하는 방법.

(프로세스 -> SMT -> PMT -> 메인 메모리)

- 장점

  - page sharing / protection이 쉬움
  - 메모리 할당 / 관리 overhead가 작음
  - 외부 단편화 X

- 단점

  - 내부 단편화 발생 가능

  - 전체 테이블 수가 증가 => 메모리 소모가 크고, Address mapping 과정 복잡
    - 접근을 3번 하지만, TLB를 두 개 둘수도..



#### (프로세스간) 페이지 공유

: 여러 프로세스가 물리 메모리 위에 있는 특정 page들을 공유한다. (fork를 통한 생성 과정에서 공유 권한 부여) 프로세스들은 공유 page를 통해 통신.



#### Demand Paging

: 프로그램 실행 시, 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 page들만 적재하는 전략. 이후 요청이 있을 때, 그 페이지를 메모리에 적재.

- 장점

  - I/O 양의 감소
  - Memory 사용량 감소
  - 빠른 응답 시간
  - 더 많은 사용자 수용




#### Page Fault

: invalid page를 접근하면 **MMU가 trap을 발생시킴 (page fault trap)**

- **Kernel mode**로 들어가서 page fault handler가 실행됨



#### 페이지 교체

: 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 페이지 부재 발생 시, 원하는 페이지를 가져오게 되는데, 이 때 물리 메모리가 모두 사용 중이라면, 기존의 page를 쫓아내고, 디스크에서 새 page를 가져오는 행위.

- 기본 방법
  - 디스크에서 필요한 page 위치 찾기
  - 빈 page frame 찾기
  - 없으면, 페이지 교체 알고리즘을 통해 희생될 page 선정
  - 희생 page를 디스크에 기록, 페이지 테이블 수정
  - 비워진 page frame에 새 page를 읽어오고, 페이지 테이블 수정
  - 프로세스 재시작



#### 페이지 교체 알고리즘

**1) FIFO(First In First Out) Algorithm**

: 먼저 들어온 page 순서대로 페이지 교체

<img src="C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\image-20210215172610158.png" alt="image-20210215172610158" style="zoom:80%;" />

- 단점)

  - 오래된 page여도 필요할 수 있다. (초기값이라면..)

  - Belady의 모순

    : page frame 개수를 늘려도 부재가 줄어들지 않고, 오히려 늘어남. (원래 page frame 개수가 늘어나면 성능도 좋아져야 정상인데..)



**2) 최적 페이지 교체 (Optimal Algorithm)**

: 미래의 참조를 알고 있다고 가정하여, 앞으로 가장 오랫동안 사용되지 않을 page를 찾아 교체. 

현실에서 실사용 불가하므로, 비교연구 목적으로 쓰임.

- 장점
  - 모든 알고리즘 중, 가장 낮은 페이지 부재율을 보장
- 단점
  - 사실상 모든 프로세스의 메모리 참조 계획을 알 수 없어 구현 불가.



(미래를 모르니 과거를 보며 알고리즘 설계..)

**3) LRU(Least Recently Used)  Algorithm**

: 가장 오랫동안 사용되지 않은 페이지를 선택해 교체. (FIFO보다 낫지만, 최적보단 성능 떨어짐.)

<img src="C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\image-20210215172850271.png" alt="image-20210215172850271" style="zoom:80%;" />



**4) LFU(Least Frequently Used) Algorithm**

: 참조 횟수가 가장 적은 페이지를 교체.

- 장점
  - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에, page의 인기도를 좀 더 정확히 반영할 수 있음
- 단점
  - 참조 시점의 최근성을 반영하지 못함
  - LRU보다 구현이 복잡



**5) MFU(Most-Frequently-Used) Algorithm**

: 참조 횟수가 가장 많은 페이지를 교체. (참조 횟수가 가장 적은 페이지는 최근에 메모리에 올라온 것이고, 따라서 앞으로 계속 사용될 것이라는 가정하에)



### 9. 캐시의 지역성

#### 캐시 메모리

: 속도가 빠른 장치와 느린 장치 간의 속도차에 따른 병목현상을 줄이기 위한 범용 메모리.

CPU가 어떤 데이터를 원할지 어느정도 예측함으로써 이 역할을 수행.

캐시 메모리(적은 용량)에 CPU가 이후 참조할, 쓸모있는 정보가 어느 정도 들어있느냐에 따라 성능이 차이남.



#### 캐시의 지역성 원리

: 적중률(hit rate)을 극대화시키기 위해 사용하는 원리로, 기억장치 내의 정보를 균일하게 접근하지 않고, 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성.

- 시간 지역성 : 최근에 참조한 주소의 내용은 다음에도 쓰일 가능성이 높다.
- 공간 지역성 : 참조된 주소와 인접한 주소의 내용이 다시 참조될 가능성이 높다.



#### Caching line

: 캐시에 바로 접근하여 데이터를 출력할 수 있도록, 캐시에 데이터를 저장할 때 특정 자료구조를 사용해 묶음으로 저장하는 것. (데이터의 메모리 주소를 기록해둔 tag를 달아놓는다.)

메모리로부터 가져올 때도 캐싱라인 기준으로 가져옴.

- 캐시 구조
  - 1) Direct map : DRAM의 여러 개의 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식
  - 2) Fully Associative : 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장.
  - 3) Set Associative : 1, 2를 섞은 중간형. 특정 로우를 지정해 그 로우 안의 어떤 열이든 비었으면 저장.



### 10. Stack vs Heap

#### Stack

: 스택 메모리는 정적 메모리 할당을 위한 것인데, 임시 데이터(함수의 호출/반환과 지역변수들)를 위해 사용한다. 접근이 빠르지만, 크기 제한이 있다. 범위가 지역적이고, 구현이 쉽다.



#### Heap

: 힙 메모리 영역은 동적으로 메모리 할당을 하기 위한 영역이다. 동적으로 메모리를 할당한다는 것은 얼만큼의 메모리를 할당해야 하는지 정적으로(컴파일 타임) 알 수 없고, 런타임에 결정된다는 뜻이다. 접근이 상대적으로 늘지만, 메모리 크기 제한이 없다. 범위가 전역적이고, 구현이 어렵다.